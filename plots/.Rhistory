G = 5
nu = 2
do_chain(p,nu,h_init,N,R,G)
do_chain <- function(p,nu,h_init,N,R,G) {
H <- matrix(nrow=G,ncol=length(h_init))
H[1,] <- h_init
for (i in 2:G) {
H[i,] <- next_gen(p,nu,H[i-1,],N,R) ## when h = c(0.5,0.5), first generation doesn't change h_new
}
#  return(H[G,])
return(H[,])
}
do_chain(p,nu,h_init,N,R,G)
a=5
a=a-3
a
a=3
if (a==3){print('y')}
a='a'
if (a=='a'){print('y')}
if (2>1 & a=='a'){print('y')}
fo (i in 1:2){print(i)}
for (i in 1:2){print(i)}
N=1000
Person=2
individual_N = log(N, 10) - log(31, 10)
prev_d <- rmultinom(1, individua_N, h_new)
h_new
prev_d <- rmultinom(1, individual_N, h_new)
a = p * nu + prev_d
individual_N
sample <- rdirichlet(1, a)
sample
individual_N = log(N / Person , 10) - log(31, 10)
individual_N
a
typeof(a)
rdirichlet(1,a)
rdirichlet(1,c(a[1],a[2]))
e=a[1]
e
typeof(e)
rdirichlet(1, c(0.24,0.76))
a_final=c(0,0)
a_final=a_final+a
a
a_final
a_final=a_final+a
a_final
Split=='even'
Split='even'
Person
N
if (Split == 'even') {
individual_N = log(N / Person , 10) - log(31, 10)
a_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, individual_N, h_new) ### each person generates an even proportion of data (total = N)
a = p * nu + prev_d
a_final = a_final + a
}
}
a_final
Split='no'
if (Split == 'no') {
individual_N = log(N, 10) - log(31, 10)
# Given the (updated) hypothesis, generate data binomially (p=c(.5,.5)), or multinomially (p=c(.3,.3,.4))
prev_d <- rmultinom(1, individual_N, h_new)
# update
# posterior: alpha* = alpha + s; beta* = beta + N - s (s is the number of a particular alternation in generated data)
# alpha, beta are shape parameters of the beta distribution
# alpha = mu * nu
# beta = (1 - mu) * nu
# p = c(mu, 1-mu)
# prev_d = s
#          N - s
# alpha* = p[0] * nu + s = p[0] * nu + prev_d[0]
# beta* = p[1] * nu + N - s = p[1] * nu + prev_d[1]
# a is the posterior beta distribution with shape alpha* and beta*
# therefore a = c(alpha*, beta*)
a = p * nu + prev_d
# choose a new hypothesis (sampling)
# since lenght(a) == 2, reduces to beta generating function
sample <- rdirichlet(1, a)
}
a
prev_d
individual_N = log(N, 10) - log(31, 10)
individual_N
prev_d <- rmultinom(1, individual_N, h_new)
prev_d
a = p * nu + prev_d
a
individual_N = log(N / Person , 10) - log(31, 10)
d_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, individual_N, h_new) ### each person generates an even proportion of data (total = N)
d_final = d_final + prev_d}
d_final
rmultinom(1,1.5,c(0.5,0.5))
log(1000,10)-log(31,10)
log(1000/31)
log(1000/31,10)
N=log(1000,10)-log(31,10)
N
Person=2
individual_N = N / Person
d_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, individual_N, h_new) ### each person generates an even proportion of data (total = N)
d_final = d_final + prev_d}
prev_d
prev_d=rmultinom(1,N,h_new)
prev_d
d_final
individual_N = N / Person
individual_N
d_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new) ### each person generates an even proportion of data (total = N)
d_final = d_final + prev_d / Person}
d_final
d_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new) ### each person generates an even proportion of data (total = N)
d_final = d_final + prev_d / Person}
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new) ### each person generates an even proportion of data (total = N)
print(prev_d)
d_final = d_final + prev_d / Person]
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new) ### each person generates an even proportion of data (total = N)
print(prev_d)
d_final = d_final + prev_d / Person}
Person=3
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new) ### each person generates an even proportion of data (total = N)
print(prev_d)
d_final = d_final + prev_d / Person}
d_final
d_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new) ### each person generates an even proportion of data (total = N)
print(prev_d)
print(prev_d/Person)
d_final = d_final + prev_d / Person}
Person=2
d_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new) ### each person generates an even proportion of data (total = N)
print(prev_d)
print(prev_d/Person)
d_final = d_final + prev_d / Person}
d_final
Person=3
d_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new) ### each person generates an even proportion of data (total = N)
print(prev_d)
print(prev_d/Person)
d_final = d_final + prev_d / Person}
d_final
rmultinom(1,2,c(0.6,0.4))
rmultinom(1,1,c(0.6,0.4))
rmultinom(1,1.5,c(0.6,0.4))
a = p * nu + d_final
d_final
rdirichlet(1,a)
Person=3
d_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new) ### each person generates an even proportion of data (total = N)
print(prev_d)
print(prev_d/Person)
d_final = d_final + prev_d / Person
}
a = p * nu + d_final
rdirichlet(1, a)
sample(1:5,size=1,replace=T)
total <- 100
n <- 4
as.vector(table(sample(1:n, size = total, replace = T)))
sample(0:1,4,replace=T)
sample(0:1,4,replace=T)
sample(0:1,4,replace=T)
?sample
sample(0:1,4,replace=T,prob=True)
sample(1:n, size = total, replace = T)
N
total=N
n=Person
n
sample(1:n, size = total, replace = T)
table(sample(1:n, size = total, replace = T))
0/3
2/3
q=0/3
w=2/3
e=1/3
q+w+e
prob = as.vector(table(sample(1:Person, size = N, replace = T)))
prob
N
Person
table(sample(1:Person, size = N, replace = T))
table(sample(1:Person,size=N,replace=T))
table(sample(1:Person,size=1000/31,replace=T))
1000/31
N
d_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new) ### each person generates an even proportion of data (total = N)
d_final = d_final + prev_d / Person
}
d_final
log(1000,10)-log(31,10)
d_final = c(0, 0)
for (i in 1:Person){
prev_d<-rmultinom(1,1000/31,h_new)
d_final = d_final + prev_d / Person
}
d_final
log(d_final,10)
N=100
prev_d <- rmultinom(1, N, h_new)
prev_d
a = p * nu + prev_d
rdirichlet(1,a)
a
d_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new) ### each person generates an even proportion of data (total = N)
d_final = d_final + prev_d / Person
}
d_final
a = p * nu + d_final
rdirichlet(1,a)
as.vector(table(sample(1:Person,size=100,replace=T)))
as.vector(table(sample(1:Person,size=1000/31,replace=T)))
as.vector(table(sample(1:Person,size=1000/31,replace=T)))/(1000/31)
prob=as.vector(table(sample(1:Person,size=1000/31,replace=T)))/(1000/31)
sum(prob)
prob[0]
prob[1]
prob[2]
prob[3]
prob
d_final = c(0, 0)
prob = as.vector(table(sample(1:Person, size = N, replace = T))) / N
prob
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new)
d_final = d_final + prevd * prob[i]
}
d_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new)
d_final = d_final + prev_d * prob[i]
}
d_final
a = p * nu + d_final
rdirichlet(1,a)
h_init = c(0.5, 0.5)
p = c(.5, .5)
G=5
n_chain=2
next_gen <- function(p, nu, h, N, R, Person, Split) {
a = 0
# apply raise-to-a-power-and-renormalize regularization
h_new <- h ^ R / sum(h ^ R)
#  h_new <- Rbeta(h, R, R, log=FALSE)
if (Split == 'no') {
# Given the (updated) hypothesis, generate data binomially (p=c(.5,.5)), or multinomially (p=c(.3,.3,.4))
prev_d <- rmultinom(1, N, h_new)
# update
# posterior: alpha* = alpha + s; beta* = beta + N - s (s is the number of a particular alternation in generated data)
# alpha, beta are shape parameters of the beta distribution
# alpha = mu * nu
# beta = (1 - mu) * nu
# p = c(mu, 1-mu)
# prev_d = s
#          N - s
# alpha* = p[0] * nu + s = p[0] * nu + prev_d[0]
# beta* = p[1] * nu + N - s = p[1] * nu + prev_d[1]
# a is the posterior beta distribution with shape alpha* and beta*
# therefore a = c(alpha*, beta*)
a = p * nu + prev_d
}
### Input to the next learner still has a total of N, yet evenly drawn from output from each previous learner ###
if (Split == 'even') {
d_final = c(0, 0)
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new) ### each person generates an even proportion of data (total = N)
d_final = d_final + prev_d / Person
}
a = p * nu + d_final
}
### Input to the next learner still has a total of N, yet randomly drawn from output from each previous learner ###
if (Split == 'random') {
d_final = c(0, 0)
prob = as.vector(table(sample(1:Person, size = N, replace = T))) / N
for (i in 1:Person) {
prev_d <- rmultinom(1, N, h_new)
d_final = d_final + prev_d * prob[i]
}
a = p * nu + d_final
}
# choose a new hypothesis (sampling)
# since lenght(a) == 2, reduces to beta generating function
sample <- rdirichlet(1, a)
return(sample)
# # choose a new hypothesis (MAP)
# MAP <- dirichMAP(a)
# return(MAP)
}
do_chain <- function(p, nu, h_init, N, R, G, Person, Split) {
H <- matrix(nrow = G,ncol = length(h_init))
H[1,] <- h_init
for (i in 2:G) {
H[i,] <- next_gen(p, nu, H[i-1,], N, R, Person, Split) ## when h = c(0.5,0.5), first generation doesn't change h_new
}
return(H[G,])
#  return(H[,]) to track variability across generations
}
do_sims <- function(p, nu, h_init, N, R, G, Person, Split, n_chain) {
replicate(n_chain,do_chain(p, nu, h_init, N, R, G, Person, Split))
}
pargrid <- list(nu = c(2), R = c(1,2,3,4)) %>% cross_df()
Person=2
Person=1
Split='no'
N = 1000/31
grid_sims <- function(nu,R) do_sims(p,nu,h_init,N,R,G,n_chain)
samples <- pmap(pargrid,grid_sims)
names(samples) <- unlist(pmap(pargrid,function(nu,R) paste("nu=",nu,"R=",R)))
n_chain=2
samples <- pmap(pargrid,grid_sims)
names(samples) <- unlist(pmap(pargrid,function(nu,R) paste("nu=",nu,"R=",R)))
grid_sims <- function(nu,R) do_sims(p,nu,h_init,N,R,G,Person,Split,n_chain)
samples <- pmap(pargrid,grid_sims)
names(samples) <- unlist(pmap(pargrid,function(nu,R) paste("nu=",nu,"R=",R)))
samples
Person=2
Split='even'
pargrid <- list(nu = c(2), R = c(1,2,3,4)) %>% cross_df()
grid_sims <- function(nu,R) do_sims(p,nu,h_init,N,R,G,Person,Split,n_chain)
samples <- pmap(pargrid,grid_sims)
names(samples) <- unlist(pmap(pargrid,function(nu,R) paste("nu=",nu,"R=",R)))
samples
install.packages('childesr')
library(childesr)
eng_na <- get_corpora(collection = "English-NA")
eng_na <- get_corpora(connection = "English-NA")
corpora <- get_corpora(connection = NULL, db_version = "current", db_args = NULL)
corpora
brown<-subset(corpora, corpus_name %in% c('Brown'))
brown
get_database_version(connection = NULL, db_version = "current", db_args = NULL)
english_tokens <- get_tokens(collection = c("Eng-NA","Eng-UK"),
role = c("target_child","Mother", "Father"),
token = "*")
d_adam_utts <- get_utterances(corpus = "Brown",
target_child = "Adam")
str(d_adam_utts)
d_adam_utts
subset(d_adam_utts, gloss %in% "there's one .")
subset(d_adam_utts, gloss %in% "there's one")
a<subset(d_adam_utts, gloss %in% "there's one")
a$num_tokens
d_adam_utts$gloss[1:20]
d_adam_utts$gloss[1:25]
d_adam_utts$gloss[1:35]
d_adam_utts$gloss[1:65]
d_adam_utts$gloss[1:100]
d_adam_utts$num_tokens[1:81]
setwd('~/Desktop/Experiments/CHILDES/')
write.csv(d_adam_utts, 'Adam.csv',row.names=FALSE)
d_adam_utts$part_of_speech[1:81]
d_adam_utts$gloss[1:81]
eng_utterances <- get_utterances(corpus = 'Brown',
target_child = "Adam",
role = c("target_child","Mother", "Father"))
eng_utterances
eng_utterances$gloss[1:81]
eng_utterances$part_of_speech[1:43]
eng_utterances <- get_utterances(corpus = 'Brown',
target_child = "Adam",
role = c("Target_child","Mother", "Father"))
eng_utterances$part_of_speech[1:43]
eng_utterances$gloss[1:81]
row.names((eng_utterances))
col.names((eng_utterances))
colnames(eng_utterances)
eng_utterances <- get_utterances(corpus = 'Brown',
target_child = "Adam")
nrow(eng_utterances)
head(eng_utterances)
eng_utterances <- get_utterances(corpus = 'Brown',
target_child = "Adam",
role = c("target_child","Mother", "Father"))
a<-head(eng_utterances, 1715)
tail(a)
tail(a$gloss)
write.csv(a, 'childesr-Adam.csv', header=T, sep = ',')
write.csv(a, 'childesr-Adam.csv', row.names=FALSE)
nrow(a)
eng_utterances <- get_utterances(corpus = 'Brown',
target_child = "Adam")
a<-head(eng_utterances,1715)
write.csv(a, 'childesr-Adam-more.csv', row.names=FALSE)
a<-eng_utterances[order(transcript_id),]
a<-subset(eng_utterances,transcript_id %in% c('3272'))
nrow(a)
eng_utterances <- get_utterances(corpus = 'Brown',
target_child = "Adam",
role = c("target_child","Mother", "Father"))
a<-subset(eng_utterances,transcript_id %in% c('3272'))
nrow(a)
write.csv(a, 'childesr-Adam.csv', row.names=FALSE)
eng_utterances <- get_tokens(corpus = 'Brown',
target_child = "Adam",
role = c("target_child","Mother", "Father"))
eng_utterances <- get_tokens(corpus = 'Brown',
target_child = "Adam",
role = c("target_child","Mother", "Father"),
token = '*')
eng_utterances$relation
colnames(eng_utterances)
setwd("~/Desktop/Experiments/dlm/codes")
setwd("~/Desktop/Experiments/dlm/plots")
library(ggplot2)
library(gridExtra)
data2<-read.csv(file="dlm-mix-prepv-new.csv",header=T,sep=",")
data2$Mean<-as.numeric(data1$Mean)
data2$Len<-factor(data2$Len,levels=c("Shorter PP closer","Longer PP closer", "Equal length"))
data2$Language<-factor(data2$Language,levels=c("English", "German", "Dutch", "Bulgarian", "Croatian","Czech",
"Russian","Slovenian","Ukrainian", "Polish"))
p2<-ggplot(data2[,],aes(x=Len,y=Mean,fill=Len)) +
geom_bar(position=position_dodge(),stat='identity',colour='black')+
geom_text(aes(label=paste(Mean,"%")), vjust=-3.5,position=position_dodge(.9),size=3)+
geom_errorbar(aes(ymin=CI25, ymax=CI975),width=.1,position=position_dodge(.9))+
scale_fill_manual(values=c("#009E73","#999999", "#E69F00"))+
labs(x="Corpus")+labs(y="Percent (%)")+labs(fill="PP ordering")+
scale_y_continuous(limits=c(0,100))+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.title.y=element_text(size=13),
axis.text.y=element_text(size=11),
strip.text = element_text(size=11),
legend.title=element_text(size=13),
legend.text=element_text(size=13)) +
theme(legend.position="top") +
facet_wrap(~Language,ncol=6)
data2<-read.csv(file="dlm-mix-prepv-new.csv",header=T,sep=",")
data2$Mean<-as.numeric(data2$Mean)
data2$Len<-factor(data2$Len,levels=c("Shorter PP closer","Longer PP closer", "Equal length"))
data2$Language<-factor(data2$Language,levels=c("English", "German", "Dutch", "Bulgarian", "Croatian","Czech",
"Russian","Slovenian","Ukrainian", "Polish"))
p2<-ggplot(data2[,],aes(x=Len,y=Mean,fill=Len)) +
geom_bar(position=position_dodge(),stat='identity',colour='black')+
geom_text(aes(label=paste(Mean,"%")), vjust=-3.5,position=position_dodge(.9),size=3)+
geom_errorbar(aes(ymin=CI25, ymax=CI975),width=.1,position=position_dodge(.9))+
scale_fill_manual(values=c("#009E73","#999999", "#E69F00"))+
labs(x="Corpus")+labs(y="Percent (%)")+labs(fill="PP ordering")+
scale_y_continuous(limits=c(0,100))+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.title.y=element_text(size=13),
axis.text.y=element_text(size=11),
strip.text = element_text(size=11),
legend.title=element_text(size=13),
legend.text=element_text(size=13)) +
theme(legend.position="top") +
facet_wrap(~Language,ncol=6)
data3<-read.csv(file="romance-dlm-mix-prepv-new.csv",header=T,sep=",")
data3$Mean<-as.numeric(data3$Mean)
data3$Len<-factor(data3$Len,levels=c("Shorter PP closer","Longer PP closer", "Equal length"))
p3<-ggplot(data3[,],aes(x=Len,y=Mean,fill=Len)) +
geom_bar(position=position_dodge(),stat='identity',colour='black')+
geom_text(aes(label=paste(Mean,"%")), vjust=-3.5,position=position_dodge(.9),size=3)+
geom_errorbar(aes(ymin=CI25, ymax=CI975),width=.1,position=position_dodge(.9))+
scale_fill_manual(values=c("#009E73","#999999", "#E69F00"))+
labs(x="Corpus")+labs(y="")+labs(fill="PP ordering")+
scale_y_continuous(limits=c(0,100))+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.title.y=element_text(size=13),
axis.text.y=element_text(size=11),
strip.text = element_text(size=11),
legend.title=element_text(size=13),
legend.text=element_text(size=13)) +
theme(legend.position="none") +
facet_wrap(~Language,ncol=6)
p4<-grid.arrange(p2,p3,nrow=2,ncol=1,widths=1:1,heights=2:1)
library(childesr)
eng_utterances <- get_tokens(corpus = 'Brown',
target_child = "Adam",
#     role = c("target_child","Mother", "Father"),
token = '*')
head(eng_utterances)
nrow(eng_utterances)
eng_utterances <- get_utterances(corpus = 'Brown',
target_child = "Adam")
nrow(eng_utterances)
write.csv(eng_utterances,'Adam_db.csv',row.names = TRUE)
pwd
pwd()
head(eng_utterances)
?lmer
max(5,8)
?get_random()
install.packages('gammit')
